# Ground-Fusion++: A Resilient Modular Multi-Sensor Fusion SLAM Framework

ðŸ’Ž Corresponding Author: [**Jie Yin æ®·æ°**](https://sjtuyinjie.github.io/) &emsp; ðŸ“ [[Paper]](TBD) &emsp; âž¡ï¸ [[Dataset]](https://github.com/sjtuyinjie/M3DGR) &emsp; â­ï¸ [[Presentation Video]](TBD) &emsp; ðŸ”¥ [[News]](TBD)

**Main contributors:** Deteng Zhang, Junjie Zhang, Yan Sun, Yihong Tian, Jie Yin*

---

## ðŸŽ¯ Introduction

This repository contains the official implementation of our **IROS 2025** paper:

> **"Towards Robust Sensor-Fusion Ground SLAM: A Comprehensive Benchmark and a Resilient Framework"**

In this work, we propose a complete solution for robust SLAM on ground robots operating under degraded conditions. Our key contributions are:

- ðŸ“¦ **[M3DGR Benchmark](https://github.com/sjtuyinjie/M3DGR)**: A comprehensive multi-sensor, multi-scenario SLAM benchmark for evaluating performance in challenging environments.  
- ðŸš€ **Ground-Fusion++ (this repo)**: A resilient and modular SLAM framework integrating heterogeneous sensors for robust localization and high-quality mapping.

---

## ðŸ”§ Key Features

- **Multi-sensor Integration:** GNSS, RGB-D camera, IMU, wheel odometer, and LiDAR.  
- **Robustness:** Combines state-of-the-art SLAM components to ensure accurate localization and mapping in large-scale, real-world scenarios.  
- **Modularity:** Designed as an extensible baseline to support future research and practical deployments in complex environments.

---

## ðŸ“¢ Notice

**2025.06.16:** Our paper has been accepted to IROS 2025!  
All datasets and code will be released soon â€” stay tuned!

<div align="center">
  <img src="https://github.com/sjtuyinjie/Ground-Fusion2/blob/main/fig/demo.gif" width="500px" alt="Ground-Fusion++ Demo">
</div>
